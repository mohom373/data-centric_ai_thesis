{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tfx in /home/vscode/.local/lib/python3.8/site-packages (1.12.0)\n",
      "Requirement already satisfied: tensorflow in /home/vscode/.local/lib/python3.8/site-packages (2.11.1)\n",
      "Requirement already satisfied: docker<5,>=4.1 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (4.4.4)\n",
      "Requirement already satisfied: packaging<21,>=20 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (20.9)\n",
      "Requirement already satisfied: portpicker<2,>=1.3.1 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.5.2)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.9.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (0.12.0)\n",
      "Requirement already satisfied: pyarrow<7,>=6 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (6.0.1)\n",
      "Requirement already satisfied: grpcio<2,>=1.28.1 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.53.0)\n",
      "Requirement already satisfied: kubernetes<13,>=10.0.1 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (12.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.24.2)\n",
      "Requirement already satisfied: pyyaml<6,>=3.12 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (5.4.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.13 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-model-analysis<0.44.0,>=0.43.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (0.43.0)\n",
      "Requirement already satisfied: attrs<22,>=19.3.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (21.4.0)\n",
      "Requirement already satisfied: tensorflow-transform<1.13.0,>=1.12.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-data-validation<1.13.0,>=1.12.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.12.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (4.5.0)\n",
      "Requirement already satisfied: click<8,>=7 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (7.1.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<3,>=2.26.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (2.34.4)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.8 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.12.11)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.40 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (2.46.0)\n",
      "Requirement already satisfied: ml-metadata<1.13.0,>=1.12.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.12.0)\n",
      "Requirement already satisfied: ml-pipelines-sdk==1.12.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.12.0)\n",
      "Requirement already satisfied: tfx-bsl<1.13.0,>=1.12.0 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (2.11.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform<1.18,>=1.6.2 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.17.1)\n",
      "Requirement already satisfied: google-apitools<1,>=0.5 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (0.5.31)\n",
      "Requirement already satisfied: jinja2<4,>=2.7.3 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (3.1.2)\n",
      "Requirement already satisfied: google-api-core<1.33 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.32.0)\n",
      "Requirement already satisfied: keras-tuner<2,>=1.0.4 in /home/vscode/.local/lib/python3.8/site-packages (from tfx) (1.3.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from tensorflow) (67.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: orjson<4.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.8.9)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.3.1.1)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.6.1)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.22.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.28.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.8.2)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.2.1)\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.21.0)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.7.3)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2023.3.23)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.7.0)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.20.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.13.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2023.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.4.2)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.18)\n",
      "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.16.3)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.6.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.18.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.35.0)\n",
      "Requirement already satisfied: google-cloud-vision<4,>=2 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.1.4)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (4.2.4)\n",
      "Requirement already satisfied: google-cloud-core<3,>=0.28.1 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.3.2)\n",
      "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.1.0)\n",
      "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.13.11)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<2.17,>=2.6.3 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (2.16.2)\n",
      "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.15.5)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.9.2)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<0.8.0,>=0.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (0.7.1)\n",
      "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.7.3)\n",
      "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (3.26.0)\n",
      "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /home/vscode/.local/lib/python3.8/site-packages (from apache-beam[gcp]<3,>=2.40->tfx) (1.3.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/vscode/.local/lib/python3.8/site-packages (from docker<5,>=4.1->tfx) (1.5.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /home/vscode/.local/lib/python3.8/site-packages (from google-api-core<1.33->tfx) (1.59.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from google-api-python-client<2,>=1.8->tfx) (3.0.1)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /home/vscode/.local/lib/python3.8/site-packages (from google-apitools<1,>=0.5->tfx) (4.1.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /home/vscode/.local/lib/python3.8/site-packages (from google-cloud-aiplatform<1.18,>=1.6.2->tfx) (2.8.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /home/vscode/.local/lib/python3.8/site-packages (from google-cloud-aiplatform<1.18,>=1.6.2->tfx) (1.6.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/vscode/.local/lib/python3.8/site-packages (from google-cloud-bigquery<3,>=2.26.0->tfx) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.8/site-packages (from jinja2<4,>=2.7.3->tfx) (2.1.2)\n",
      "Requirement already satisfied: kt-legacy in /home/vscode/.local/lib/python3.8/site-packages (from keras-tuner<2,>=1.0.4->tfx) (1.0.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/vscode/.local/lib/python3.8/site-packages (from kubernetes<13,>=10.0.1->tfx) (2022.12.7)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/vscode/.local/lib/python3.8/site-packages (from kubernetes<13,>=10.0.1->tfx) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib in /home/vscode/.local/lib/python3.8/site-packages (from kubernetes<13,>=10.0.1->tfx) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vscode/.local/lib/python3.8/site-packages (from packaging<21,>=20->tfx) (3.0.9)\n",
      "Requirement already satisfied: psutil in /home/vscode/.local/lib/python3.8/site-packages (from portpicker<2,>=1.3.1->tfx) (5.9.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/vscode/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/vscode/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/vscode/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorflow-metadata<1.13,>=1.12.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow-data-validation<1.13.0,>=1.12.0->tfx) (1.12.0)\n",
      "Requirement already satisfied: pandas<2,>=1.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow-data-validation<1.13.0,>=1.12.0->tfx) (1.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow-data-validation<1.13.0,>=1.12.0->tfx) (1.2.0)\n",
      "Requirement already satisfied: pyfarmhash<0.4,>=0.2 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow-data-validation<1.13.0,>=1.12.0->tfx) (0.3.2)\n",
      "Requirement already satisfied: ipython<8,>=7 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (7.34.0)\n",
      "Requirement already satisfied: scipy<2,>=1.4.1 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.10.1)\n",
      "Requirement already satisfied: ipywidgets<8,>=7 in /home/vscode/.local/lib/python3.8/site-packages (from tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (7.7.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/vscode/.local/lib/python3.8/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tfx) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/vscode/.local/lib/python3.8/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tfx) (0.2.8)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /home/vscode/.local/lib/python3.8/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.40->tfx) (0.12.6)\n",
      "Requirement already satisfied: grpcio-status>=1.16.0 in /home/vscode/.local/lib/python3.8/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.40->tfx) (1.48.2)\n",
      "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /home/vscode/.local/lib/python3.8/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.40->tfx) (6.5.0)\n",
      "Requirement already satisfied: sqlparse>=0.3.0 in /home/vscode/.local/lib/python3.8/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.40->tfx) (0.4.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/vscode/.local/lib/python3.8/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx) (1.5.0)\n",
      "Requirement already satisfied: docopt in /home/vscode/.local/lib/python3.8/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.40->tfx) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.7.5)\n",
      "Requirement already satisfied: backcall in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (5.9.0)\n",
      "Requirement already satisfied: decorator in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (3.0.38)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (4.8.0)\n",
      "Requirement already satisfied: pygments in /home/vscode/.local/lib/python3.8/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.14.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.4 in /home/vscode/.local/lib/python3.8/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (3.6.4)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/vscode/.local/lib/python3.8/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/vscode/.local/lib/python3.8/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (6.22.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.1.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/vscode/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/vscode/.local/lib/python3.8/site-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tfx) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tfx) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx) (3.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/vscode/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/vscode/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.6.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/vscode/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (6.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/vscode/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.5.6)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/vscode/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (5.3.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/vscode/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.1.3)\n",
      "Requirement already satisfied: pyzmq>=20 in /home/vscode/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (25.0.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/vscode/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (8.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/vscode/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/vscode/.local/lib/python3.8/site-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/vscode/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.2.6)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/vscode/.local/lib/python3.8/site-packages (from widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (6.5.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/vscode/.local/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (3.2.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /home/vscode/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (7.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/vscode/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/vscode/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/vscode/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/vscode/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /home/vscode/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.5.4)\n",
      "Requirement already satisfied: nbformat in /home/vscode/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (5.8.0)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /home/vscode/.local/lib/python3.8/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.5.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.0.5)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.2.2)\n",
      "Requirement already satisfied: tinycss2 in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.2.1)\n",
      "Requirement already satisfied: defusedxml in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.5.0)\n",
      "Requirement already satisfied: bleach in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (6.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.7.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/vscode/.local/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (4.12.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/vscode/.local/lib/python3.8/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in /home/vscode/.local/lib/python3.8/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.16.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/vscode/.local/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (5.12.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.3.10)\n",
      "Requirement already satisfied: jupyter-server-terminals in /home/vscode/.local/lib/python3.8/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.4.4)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/vscode/.local/lib/python3.8/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (3.6.2)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /home/vscode/.local/lib/python3.8/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.6.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/vscode/.local/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.local/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.4)\n",
      "Requirement already satisfied: webencodings in /home/vscode/.local/lib/python3.8/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.5.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vscode/.local/lib/python3.8/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.21)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/vscode/.local/lib/python3.8/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.1.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/vscode/.local/lib/python3.8/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (0.1.4)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/vscode/.local/lib/python3.8/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.0.7)\n",
      "Requirement already satisfied: fqdn in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.5.1)\n",
      "Requirement already satisfied: uri-template in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (2.3)\n",
      "Requirement already satisfied: isoduration in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (20.11.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/vscode/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/vscode/.local/lib/python3.8/site-packages (from isoduration->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.44.0,>=0.43.0->tfx) (1.2.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --user tfx tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tensorflow is correctly installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.1\n",
      "TFX version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PIPELINE_NAME = \"penguin-simple\"\n",
    "SCHEMA_PIPELINE_NAME = \"penguin-tfdv-schema\"\n",
    "\n",
    "# Output Dir for pipeline and schema\n",
    "SCHEMA_PIPELINE_ROOT = os.path.join('pipelines', SCHEMA_PIPELINE_NAME)\n",
    "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
    "\n",
    "# Metadata / SQL dir\n",
    "SCHEMA_METADATA_PATH = os.path.join('metadata', SCHEMA_PIPELINE_NAME,\n",
    "                                    'metadata.db')\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
    "\n",
    "# Model output dir\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO) # Set default logging level "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare example CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tfx-data/data.csv', <http.client.HTTPMessage at 0x7f3ff482ff10>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = os.path.join('tfx-data')\n",
    "\n",
    "if not (os.path.exists(DATA_DIR)):\n",
    "  os.mkdir(DATA_DIR)\n",
    "\n",
    "# We download dataset from this URL\n",
    "_data_url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
    "_data_filepath = os.path.join(DATA_DIR, \"data.csv\")\n",
    "\n",
    "urllib.request.urlretrieve(_data_url, _data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species,culmen_length_mm,culmen_depth_mm,flipper_length_mm,body_mass_g\n",
      "0,0.2545454545454545,0.6666666666666666,0.15254237288135594,0.2916666666666667\n",
      "0,0.26909090909090905,0.5119047619047618,0.23728813559322035,0.3055555555555556\n",
      "0,0.29818181818181805,0.5833333333333334,0.3898305084745763,0.1527777777777778\n",
      "0,0.16727272727272732,0.7380952380952381,0.3559322033898305,0.20833333333333334\n",
      "0,0.26181818181818167,0.892857142857143,0.3050847457627119,0.2638888888888889\n",
      "0,0.24727272727272717,0.5595238095238096,0.15254237288135594,0.2569444444444444\n",
      "0,0.25818181818181823,0.773809523809524,0.3898305084745763,0.5486111111111112\n",
      "0,0.32727272727272727,0.5357142857142859,0.1694915254237288,0.1388888888888889\n",
      "0,0.23636363636363636,0.9642857142857142,0.3220338983050847,0.3055555555555556\n"
     ]
    }
   ],
   "source": [
    "!head {_data_filepath}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trainer_module_file = 'penguin_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguin_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "_FEATURE_KEYS = [\n",
    "  'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
    "]\n",
    "\n",
    "_LABEL_KEY = 'species'\n",
    "\n",
    "_TRAIN_BATCH_SIZE = 20\n",
    "_EVAL_BATCH_SIZE = 10\n",
    "\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "           for feature in _FEATURE_KEYS\n",
    "       },\n",
    "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "def _input_fn(file_pattern: List[str], \n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int = 200) -> tf.data.Dataset:\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "    file_pattern,\n",
    "    tfxio.TensorFlowDatasetOptions(\n",
    "        batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "    schema=schema).repeat()\n",
    "\n",
    "def _build_keras_model() -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
    "\n",
    "  Returns:\n",
    "    A Keras Model.\n",
    "  \"\"\"\n",
    "  # The model below is built with Functional API, please refer to\n",
    "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
    "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
    "  d = keras.layers.concatenate(inputs)\n",
    "  for _ in range(2):\n",
    "    d = keras.layers.Dense(8, activation='relu')(d)\n",
    "  outputs = keras.layers.Dense(3)(d)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(1e-2),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  model.summary(print_fn=logging.info)\n",
    "  return model\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
    "  # version provided by pipeline author. A schema can also derived from TFT\n",
    "  # graph if a Transform component is used. In the case when either is missing,\n",
    "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
    "  # feature_spec, but the schema returned would be very primitive.\n",
    "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
    "  \n",
    "  print(\"Generated Schema: \\n\", schema)\n",
    "  \n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_TRAIN_BATCH_SIZE)\n",
    "  \n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "  model = _build_keras_model()\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "  # directory.\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create actual TFX pipeline now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.proto import example_gen_pb2\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
    "  output_config = example_gen_pb2.Output(\n",
    "      split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=6),\n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=2),\n",
    "        example_gen_pb2.SplitConfig.Split(name='test', hash_buckets=2)\n",
    "      ])\n",
    "  )\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root, output_config=output_config)\n",
    "\n",
    "  # Lets create some statistics\n",
    "  statistics_gen = tfx.components.StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "  \n",
    "  # Let's create a schema based on the statistics\n",
    "  schema_gen = tfx.components.SchemaGen(statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "  \n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      statistics_gen,\n",
    "      schema_gen,\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata\n",
    "      .sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Generating ephemeral wheel package for '/workspaces/data-centric_ai_bsc_thesis/penguin_trainer.py' (including modules: ['penguin_trainer']).\n",
      "INFO:absl:User module package has hash fingerprint version 708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be.\n",
      "INFO:absl:Executing: ['/usr/local/bin/python', '/tmp/tmpzm8qfvdi/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmp8xxuua7m', '--dist-dir', '/tmp/tmpawnfhnao']\n",
      "/usr/local/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "INFO:absl:Successfully built user code wheel distribution at 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl'; target user module is 'penguin_trainer'.\n",
      "INFO:absl:Full user module path is 'penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl'\n",
      "INFO:absl:Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Pusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"SchemaGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.schema_gen.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Trainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  database_connection_config {\n",
      "    sqlite {\n",
      "      filename_uri: \"metadata/penguin-tfdv-schema/metadata.db\"\n",
      "      connection_mode: READWRITE_OPENCREATE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"metadata/penguin-tfdv-schema/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "INFO:absl:Component CsvExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tfx-data\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 6,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"eval\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:[CsvExampleGen] Resolved inputs: ({},)\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 6\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=6, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/6\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1680617863,sum_checksum:1680617863\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'output_file_format': 5, 'input_base': 'tfx-data', 'output_data_format': 6, 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 6,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"eval\"\\n      },\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"test\"\\n      }\\n    ]\\n  }\\n}', 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:25648,xor_checksum:1680617863,sum_checksum:1680617863'}, execution_output_uri='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/executor_execution/6/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/stateful_working_dir/2023-04-04T14:17:44.645749', tmp_dir='pipelines/penguin-tfdv-schema/CsvExampleGen/.system/executor_execution/6/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tfx-data\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 6,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"eval\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='2023-04-04T14:17:44.645749')\n",
      "INFO:absl:Generating examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying penguin_trainer.py -> build/lib\n",
      "installing to /tmp/tmp8xxuua7m\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/penguin_trainer.py -> /tmp/tmp8xxuua7m\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmp8xxuua7m/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmp8xxuua7m/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be.dist-info/WHEEL\n",
      "creating '/tmp/tmpawnfhnao/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl' and adding '/tmp/tmp8xxuua7m' to it\n",
      "adding 'penguin_trainer.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be.dist-info/RECORD'\n",
      "removing /tmp/tmp8xxuua7m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Processing input csv data tfx-data/* to TFExample.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "INFO:absl:Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 6 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/6\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1680617863,sum_checksum:1680617863\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 6\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen is finished.\n",
      "INFO:absl:Component StatisticsGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 7\n",
      "type_id: 15\n",
      "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1680617863,sum_checksum:1680617863\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617865852\n",
      "last_update_time_since_epoch: 1680617865852\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 7\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=7, input_dict={'examples': [Artifact(artifact: id: 7\n",
      "type_id: 15\n",
      "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1680617863,sum_checksum:1680617863\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617865852\n",
      "last_update_time_since_epoch: 1680617865852\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/7\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines/penguin-tfdv-schema/StatisticsGen/.system/executor_execution/7/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/StatisticsGen/.system/stateful_working_dir/2023-04-04T14:17:44.645749', tmp_dir='pipelines/penguin-tfdv-schema/StatisticsGen/.system/executor_execution/7/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='2023-04-04T14:17:44.645749')\n",
      "INFO:absl:Generating statistics for split train.\n",
      "INFO:absl:Statistics for split train written to pipelines/penguin-tfdv-schema/StatisticsGen/statistics/7/Split-train.\n",
      "INFO:absl:Generating statistics for split eval.\n",
      "INFO:absl:Statistics for split eval written to pipelines/penguin-tfdv-schema/StatisticsGen/statistics/7/Split-eval.\n",
      "INFO:absl:Generating statistics for split test.\n",
      "INFO:absl:Statistics for split test written to pipelines/penguin-tfdv-schema/StatisticsGen/statistics/7/Split-test.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 7 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/7\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}) for execution 7\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component StatisticsGen is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Trainer] Resolved inputs: ({'examples': [Artifact(artifact: id: 7\n",
      "type_id: 15\n",
      "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1680617863,sum_checksum:1680617863\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617865852\n",
      "last_update_time_since_epoch: 1680617865852\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 8\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={'examples': [Artifact(artifact: id: 7\n",
      "type_id: 15\n",
      "uri: \"pipelines/penguin-tfdv-schema/CsvExampleGen/examples/6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1680617863,sum_checksum:1680617863\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617865852\n",
      "last_update_time_since_epoch: 1680617865852\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model_run/8\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model/8\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'module_path': 'penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl', 'custom_config': 'null', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'train_args': '{\\n  \"num_steps\": 100\\n}'}, execution_output_uri='pipelines/penguin-tfdv-schema/Trainer/.system/executor_execution/8/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/Trainer/.system/stateful_working_dir/2023-04-04T14:17:44.645749', tmp_dir='pipelines/penguin-tfdv-schema/Trainer/.system/executor_execution/8/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='2023-04-04T14:17:44.645749')\n",
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "INFO:absl:udf_utils.get_fn {'module_path': 'penguin_trainer@pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl', 'custom_config': 'null', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'train_args': '{\\n  \"num_steps\": 100\\n}'} 'run_fn'\n",
      "INFO:absl:Installing 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/usr/local/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp5amsuf_l', 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "INFO:absl:Successfully installed 'pipelines/penguin-tfdv-schema/_wheels/tfx_user_code_Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+708e8ddbcd9f327c140b552c729957b7701bd70fd339539000385419a51de4be\n",
      "Generated Schema: \n",
      " feature {\n",
      "  name: \"body_mass_g\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"culmen_depth_mm\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"culmen_length_mm\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"flipper_length_mm\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"species\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Model: \"model_3\"\n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl: Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl: culmen_length_mm (InputLayer)  [(None, 1)]          0           []                               \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl: culmen_depth_mm (InputLayer)   [(None, 1)]          0           []                               \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl: flipper_length_mm (InputLayer)  [(None, 1)]         0           []                               \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl: body_mass_g (InputLayer)       [(None, 1)]          0           []                               \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl: concatenate_3 (Concatenate)    (None, 4)            0           ['culmen_length_mm[0][0]',       \n",
      "INFO:absl:                                                                  'culmen_depth_mm[0][0]',        \n",
      "INFO:absl:                                                                  'flipper_length_mm[0][0]',      \n",
      "INFO:absl:                                                                  'body_mass_g[0][0]']            \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl: dense_9 (Dense)                (None, 8)            40          ['concatenate_3[0][0]']          \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl: dense_10 (Dense)               (None, 8)            72          ['dense_9[0][0]']                \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl: dense_11 (Dense)               (None, 3)            27          ['dense_10[0][0]']               \n",
      "INFO:absl:                                                                                                  \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Total params: 139\n",
      "INFO:absl:Trainable params: 139\n",
      "INFO:absl:Non-trainable params: 0\n",
      "INFO:absl:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 3ms/step - loss: 0.6746 - sparse_categorical_accuracy: 0.7405 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/penguin-tfdv-schema/Trainer/model/8/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/penguin-tfdv-schema/Trainer/model/8/Format-Serving/assets\n",
      "INFO:absl:Training complete. Model written to pipelines/penguin-tfdv-schema/Trainer/model/8/Format-Serving. ModelRun written to pipelines/penguin-tfdv-schema/Trainer/model_run/8\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 8 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model_run/8\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Trainer/model/8\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 8\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/penguin-simple\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Pusher] Resolved inputs: ({'model': [Artifact(artifact: id: 10\n",
      "type_id: 20\n",
      "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/8\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617873698\n",
      "last_update_time_since_epoch: 1680617873698\n",
      ", artifact_type: id: 20\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 9\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=9, input_dict={'model': [Artifact(artifact: id: 10\n",
      "type_id: 20\n",
      "uri: \"pipelines/penguin-tfdv-schema/Trainer/model/8\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617873698\n",
      "last_update_time_since_epoch: 1680617873698\n",
      ", artifact_type: id: 20\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Pusher/pushed_model/9\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'custom_config': 'null', 'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"serving_model/penguin-simple\"\\n  }\\n}'}, execution_output_uri='pipelines/penguin-tfdv-schema/Pusher/.system/executor_execution/9/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/Pusher/.system/stateful_working_dir/2023-04-04T14:17:44.645749', tmp_dir='pipelines/penguin-tfdv-schema/Pusher/.system/executor_execution/9/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/penguin-simple\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='2023-04-04T14:17:44.645749')\n",
      "WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.\n",
      "INFO:absl:Model version: 1680617873\n",
      "INFO:absl:Model written to serving path serving_model/penguin-simple/1680617873.\n",
      "INFO:absl:Model pushed to pipelines/penguin-tfdv-schema/Pusher/pushed_model/9.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 9 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/Pusher/pushed_model/9\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 9\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n",
      "INFO:absl:Component SchemaGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 8\n",
      "type_id: 17\n",
      "uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617870603\n",
      "last_update_time_since_epoch: 1680617870603\n",
      ", artifact_type: id: 17\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 10\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=10, input_dict={'statistics': [Artifact(artifact: id: 8\n",
      "type_id: 17\n",
      "uri: \"pipelines/penguin-tfdv-schema/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"published\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.12.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1680617870603\n",
      "last_update_time_since_epoch: 1680617870603\n",
      ", artifact_type: id: 17\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/SchemaGen/schema/10\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='pipelines/penguin-tfdv-schema/SchemaGen/.system/executor_execution/10/executor_output.pb', stateful_working_dir='pipelines/penguin-tfdv-schema/SchemaGen/.system/stateful_working_dir/2023-04-04T14:17:44.645749', tmp_dir='pipelines/penguin-tfdv-schema/SchemaGen/.system/executor_execution/10/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2023-04-04T14:17:44.645749\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2023-04-04T14:17:44.645749\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='2023-04-04T14:17:44.645749')\n",
      "INFO:absl:Processing schema from statistics for split train.\n",
      "INFO:absl:Processing schema from statistics for split eval.\n",
      "INFO:absl:Processing schema from statistics for split test.\n",
      "INFO:absl:Schema written to pipelines/penguin-tfdv-schema/SchemaGen/schema/10/schema.pbtxt.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 10 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines/penguin-tfdv-schema/SchemaGen/schema/10\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}) for execution 10\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component SchemaGen is finished.\n"
     ]
    }
   ],
   "source": [
    "tfx.orchestration.LocalDagRunner().run(\n",
    "  _create_pipeline(\n",
    "      pipeline_name=SCHEMA_PIPELINE_NAME,\n",
    "      pipeline_root=SCHEMA_PIPELINE_ROOT,\n",
    "      data_root=DATA_DIR,\n",
    "      module_file=_trainer_module_file,\n",
    "      serving_model_dir=SERVING_MODEL_DIR,\n",
    "      metadata_path=SCHEMA_METADATA_PATH))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review output of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metadata.proto import metadata_store_pb2\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.portable.mlmd import execution_lib\n",
    "\n",
    "# TODO(b/171447278): Move these functions into the TFX library.\n",
    "\n",
    "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
    "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
    "  context = metadata.store.get_context_by_type_and_name(\n",
    "      'node', f'{pipeline_name}.{component_id}')\n",
    "  executions = metadata.store.get_executions_by_context(context.id)\n",
    "  latest_execution = max(executions,\n",
    "                         key=lambda e:e.last_update_time_since_epoch)\n",
    "  return execution_lib.get_output_artifacts(metadata, latest_execution.id)\n",
    "\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.experimental.interactive import visualizations\n",
    "\n",
    "def visualize_artifacts(artifacts):\n",
    "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
    "  for artifact in artifacts:\n",
    "    visualization = visualizations.get_registry().get_visualization(\n",
    "        artifact.type_name)\n",
    "    if visualization:\n",
    "      visualization.display(artifact)\n",
    "\n",
    "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
    "standard_visualizations.register_standard_visualizations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    }
   ],
   "source": [
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.metadata import Metadata\n",
    "from tfx.types import standard_component_specs\n",
    "\n",
    "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
    "    SCHEMA_METADATA_PATH)\n",
    "with Metadata(metadata_connection_config) as metadata_handler:\n",
    "  # Find output artifacts from MLMD.\n",
    "  stat_gen_output = get_latest_artifacts(metadata_handler, SCHEMA_PIPELINE_NAME,\n",
    "                                         'StatisticsGen')\n",
    "  stats_artifacts = stat_gen_output[standard_component_specs.STATISTICS_KEY]\n",
    "\n",
    "  schema_gen_output = get_latest_artifacts(metadata_handler,\n",
    "                                           SCHEMA_PIPELINE_NAME, 'SchemaGen')\n",
    "  schema_artifacts = schema_gen_output[standard_component_specs.SCHEMA_KEY]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>html[theme=dark] iframe {background: white;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'test' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# docs-infra: no-execute\n",
    "visualize_artifacts(stats_artifacts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'body_mass_g'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'culmen_depth_mm'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'culmen_length_mm'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'flipper_length_mm'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'species'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Type  Presence Valency Domain\n",
       "Feature name                                       \n",
       "'body_mass_g'        FLOAT  required              -\n",
       "'culmen_depth_mm'    FLOAT  required              -\n",
       "'culmen_length_mm'   FLOAT  required              -\n",
       "'flipper_length_mm'  FLOAT  required              -\n",
       "'species'              INT  required              -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_artifacts(schema_artifacts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
